{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cc2cb4d",
   "metadata": {},
   "source": [
    "## 1. Configuration (matches `main.py`)\n",
    "\n",
    "> This notebook mirrors the behavior of `main.py`, but is split into inspectable steps so you can tweak parameters and rerun parts interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b16e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  NUM_AGENTS=10\n",
      "  STREAM_NAME='agent_stream'\n",
      "  REDIS_HOST='localhost':6379\n",
      "  RUN_DURATION_SECONDS=120\n",
      "  USE_LOCAL_LLM=True\n",
      "  ENABLE_STANCE_WORKER=False (batch_size=5, interval=30s)\n",
      "  ENABLE_EMBEDDING_CONTEXT=True (top_k=8, rolling_max=2000)\n",
      "  PROFILE_WINDOW_SIZE=50 PROFILE_SEED_WEIGHT=5.0\n",
      "  TOPOLOGY_LOG_INTERVAL_S=5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuration (mirrors main.py)\n",
    "NUM_AGENTS = 10\n",
    "STREAM_NAME = \"agent_stream\"\n",
    "REDIS_HOST = \"localhost\"\n",
    "REDIS_PORT = 6379\n",
    "RUN_DURATION_SECONDS = 120\n",
    "\n",
    "# Runtime switches\n",
    "USE_LOCAL_LLM = True\n",
    "ENABLE_STANCE_WORKER = False\n",
    "STANCE_BATCH_SIZE = 5\n",
    "STANCE_BATCH_INTERVAL = 30\n",
    "\n",
    "# Embedding-based context + topology (requires OPENAI_API_KEY)\n",
    "ENABLE_EMBEDDING_CONTEXT = True\n",
    "ROLLING_STORE_MAX_ITEMS = 2000\n",
    "CONTEXT_TOP_K = 8\n",
    "PROFILE_WINDOW_SIZE = 50\n",
    "PROFILE_SEED_WEIGHT = 5.0\n",
    "\n",
    "# Topology logging cadence\n",
    "TOPOLOGY_LOG_INTERVAL_S = 5.0\n",
    "\n",
    "# Prompt template used by `main.py` (fixed stance sentence is authoritative)\n",
    "initial_prompt_template = (\n",
    "   \"You are participating in a social-media-style discussion about {topic}.\" \\\n",
    "   \"The sentence {unique_prompt} is your fixed stance and is authoritative and exhaustive. Write entirely from the worldview, assumptions, tone, values, and constraints it defines; it fully determines what you believe, how you speak, and what claims you are willing to make.\" \\\n",
    "   \"Produce a short, attention-grabbing post that hooks readers, makes a clear and strong claim aligned with that grounding, and invites engagement (likes, replies, shares).\" \\\n",
    "   \"Be concise, bold, and evocative. Use a distinct memorable opening line, assertive language, and a direct call-to-action every time. Emulate authentic social media posts.\" \\\n",
    "   \"Make sure posts are distinct, do not copy formatting and language of previous posts, instead contradict any claims that oppose your fixed stance\"\n",
    "   \"Do not introduce outside viewpoints, neutral framing, balance, or meta-commentary. Do not soften or qualify claims unless explicitly required by the authoritative sentence. Never refer to yourself as an agent, AI, or participant in a debate.\"\n",
    " )\n",
    "\n",
    "# Initial instruction to Agent 1 (matches `main.py`)\n",
    "STARTER_USER_INSTRUCTION = (\n",
    "    \"Write the first viral post that kicks off a heated comment thread about this topic. \"\n",
    "    \"Make a strong claim, then invite replies.\"\n",
    " )\n",
    "\n",
    "print(\n",
    "    \"Configuration:\\n\"\n",
    "    f\"  NUM_AGENTS={NUM_AGENTS}\\n\"\n",
    "    f\"  STREAM_NAME={STREAM_NAME!r}\\n\"\n",
    "    f\"  REDIS_HOST={REDIS_HOST!r}:{REDIS_PORT}\\n\"\n",
    "    f\"  RUN_DURATION_SECONDS={RUN_DURATION_SECONDS}\\n\"\n",
    "    f\"  USE_LOCAL_LLM={USE_LOCAL_LLM}\\n\"\n",
    "    f\"  ENABLE_STANCE_WORKER={ENABLE_STANCE_WORKER} (batch_size={STANCE_BATCH_SIZE}, interval={STANCE_BATCH_INTERVAL}s)\\n\"\n",
    "    f\"  ENABLE_EMBEDDING_CONTEXT={ENABLE_EMBEDDING_CONTEXT} (top_k={CONTEXT_TOP_K}, rolling_max={ROLLING_STORE_MAX_ITEMS})\\n\"\n",
    "    f\"  PROFILE_WINDOW_SIZE={PROFILE_WINDOW_SIZE} PROFILE_SEED_WEIGHT={PROFILE_SEED_WEIGHT}\\n\"\n",
    "    f\"  TOPOLOGY_LOG_INTERVAL_S={TOPOLOGY_LOG_INTERVAL_S}\\n\"\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e97e07d",
   "metadata": {},
   "source": [
    "## 2. Imports (Jupyter async-friendly)\n",
    "\n",
    "Notes on coroutines in Jupyter:\n",
    "- Prefer top-level `await` over `asyncio.run(...)` (which can error in notebooks).\n",
    "- This notebook applies `nest_asyncio` so you can rerun cells without event-loop conflicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e33402ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sammli/llm-network/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful\n",
      "OPENAI_API_KEY set: True\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Allow re-entrant event loops (helps with reruns)\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()\n",
    "\n",
    "from agents.network_agent import NetworkAgent\n",
    "from agents.llm_service import LLMService\n",
    "from agents.local_llm import HuggingFaceLLM\n",
    "from agents.prompt_configs.generate_prompt import PromptGenerator\n",
    "\n",
    "from controller.stance_analysis.embedding_analyzer import EmbeddingAnalyzer\n",
    "from controller.stance_analysis.rolling_embedding_store import RollingEmbeddingStore\n",
    "from controller.stance_analysis.agent_profile_store import AgentProfileStore\n",
    "from controller.stance_analysis.network_topology import NetworkTopologyTracker\n",
    "\n",
    "from controller.time_manager import TimeManager\n",
    "from controller.order_manager import OrderManager\n",
    "from controller.stance_worker import StanceWorker\n",
    "\n",
    "from network.cache import RedisCache\n",
    "from network.stream import RedisStream\n",
    "\n",
    "from logs.logger import Logger, console_logger\n",
    "from logs.topology_logger import TopologyLogger\n",
    "\n",
    "print(\"Imports successful\")\n",
    "print(\"OPENAI_API_KEY set:\", bool(os.getenv(\"OPENAI_API_KEY\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca3bb7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NotebookRedisStream patch applied: blocking Redis ops moved to threads\n"
     ]
    }
   ],
   "source": [
    "# Notebook-only fix: run RedisStream blocking calls off the event loop.\n",
    "#\n",
    "# Why: `network/stream.py` uses the synchronous redis client inside `async def` methods.\n",
    "# In a notebook, that can starve the event loop so agent consumer tasks don't run while you `await asyncio.sleep(...)`.\n",
    "# This patch keeps the repo code untouched by monkeypatching RedisStream in-memory for this notebook session.\n",
    "\n",
    "import redis\n",
    "import network.stream as _stream_mod\n",
    "import agents.network_agent as _network_agent_mod\n",
    "import controller.order_manager as _order_manager_mod\n",
    "\n",
    "\n",
    "class NotebookRedisStream(_stream_mod.RedisStream):\n",
    "    async def create_consumer_group(self, stream_name, group_name):\n",
    "        try:\n",
    "            await asyncio.to_thread(self.redis.xgroup_create, stream_name, group_name, id='0', mkstream=True)\n",
    "            console_logger.info(f\"Consumer group '{group_name}' created for stream '{stream_name}'.\")\n",
    "        except redis.exceptions.ResponseError as e:\n",
    "            if \"BUSYGROUP\" in str(e):\n",
    "                console_logger.info(f\"Consumer group '{group_name}' already exists for stream '{stream_name}'.\")\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "    async def publish_message(self, stream_name, message_data: dict):\n",
    "        message_id = await asyncio.to_thread(self.redis.xadd, stream_name, message_data)\n",
    "        console_logger.info(f\"Message {message_id} published to stream '{stream_name}'.\")\n",
    "        return message_id\n",
    "\n",
    "    async def consume_messages(self, stream_name, group_name, consumer_name):\n",
    "        while True:\n",
    "            messages = await asyncio.to_thread(\n",
    "                self.redis.xreadgroup,\n",
    "                group_name,\n",
    "                consumer_name,\n",
    "                {stream_name: '>'},\n",
    "                1,\n",
    "                1000,\n",
    "            )\n",
    "            if messages:\n",
    "                for stream, message_list in messages:\n",
    "                    for message_id, message_data in message_list:\n",
    "                        yield message_id, message_data\n",
    "                        await asyncio.to_thread(self.redis.xack, stream_name, group_name, message_id)\n",
    "            await asyncio.sleep(0.1)\n",
    "\n",
    "    async def cleanup_stream(self, stream_name: str, num_groups=None, group_prefix: str = 'group_'):\n",
    "        try:\n",
    "            if num_groups is not None:\n",
    "                for i in range(num_groups):\n",
    "                    group = f\"{group_prefix}{i+1}\"\n",
    "                    try:\n",
    "                        await asyncio.to_thread(self.redis.xgroup_destroy, stream_name, group)\n",
    "                        console_logger.info(f\"Destroyed consumer group '{group}' on stream '{stream_name}'.\")\n",
    "                    except redis.exceptions.ResponseError as e:\n",
    "                        console_logger.info(f\"Could not destroy group '{group}': {e}\")\n",
    "            else:\n",
    "                try:\n",
    "                    groups = await asyncio.to_thread(self.redis.xinfo_groups, stream_name)\n",
    "                    for g in groups:\n",
    "                        group_name = g.get('name') if isinstance(g, dict) else g['name']\n",
    "                        try:\n",
    "                            await asyncio.to_thread(self.redis.xgroup_destroy, stream_name, group_name)\n",
    "                            console_logger.info(f\"Destroyed consumer group '{group_name}' on stream '{stream_name}'.\")\n",
    "                        except Exception as ex:\n",
    "                            console_logger.info(f\"Could not destroy group '{group_name}': {ex}\")\n",
    "                except redis.exceptions.ResponseError as e:\n",
    "                    console_logger.info(f\"No groups found for stream '{stream_name}': {e}\")\n",
    "\n",
    "            try:\n",
    "                deleted = await asyncio.to_thread(self.redis.delete, stream_name)\n",
    "                console_logger.info(f\"Deleted stream '{stream_name}' (deleted={deleted}).\")\n",
    "            except Exception as e:\n",
    "                console_logger.info(f\"Failed to delete stream '{stream_name}': {e}\")\n",
    "        except Exception as e:\n",
    "            console_logger.info(f\"Unexpected error during cleanup of stream '{stream_name}': {e}\")\n",
    "\n",
    "\n",
    "_stream_mod.RedisStream = NotebookRedisStream\n",
    "_network_agent_mod.RedisStream = NotebookRedisStream\n",
    "_order_manager_mod.RedisStream = NotebookRedisStream\n",
    "RedisStream = NotebookRedisStream  # rebind local name used in later cells\n",
    "\n",
    "print(\"NotebookRedisStream patch applied: blocking Redis ops moved to threads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd330a12",
   "metadata": {},
   "source": [
    "## 3. Preflight (rerun safety + Redis check)\n",
    "\n",
    "If you rerun the notebook, it’s important to stop background tasks first (agent consumers, topology loop, logger threads)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74523826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redis ping: True\n"
     ]
    }
   ],
   "source": [
    "# Best-effort cleanup from a previous notebook run\n",
    "async def _stop_previous_run_if_any():\n",
    "    # Stop agents\n",
    "    if \"agents\" in globals():\n",
    "        for a in list(globals().get(\"agents\") or []):\n",
    "            try:\n",
    "                await a.stop()\n",
    "            except Exception as exc:\n",
    "                print(f\"Warning: failed stopping agent {getattr(a,'id','?')}: {exc}\")\n",
    "        globals()[\"agents\"] = []\n",
    "\n",
    "    # Cancel topology task\n",
    "    topo_task = globals().get(\"topo_task\")\n",
    "    if topo_task is not None:\n",
    "        try:\n",
    "            topo_task.cancel()\n",
    "            await topo_task\n",
    "        except asyncio.CancelledError:\n",
    "            pass\n",
    "        except Exception as exc:\n",
    "            print(f\"Warning: topology task cancel error: {exc}\")\n",
    "        globals()[\"topo_task\"] = None\n",
    "\n",
    "    # Stop topology logger thread\n",
    "    topology_logger = globals().get(\"topology_logger\")\n",
    "    if topology_logger is not None:\n",
    "        try:\n",
    "            topology_logger.stop()\n",
    "        except Exception as exc:\n",
    "            print(f\"Warning: topology_logger.stop() failed: {exc}\")\n",
    "        globals()[\"topology_logger\"] = None\n",
    "\n",
    "    # Stop stance worker\n",
    "    stance_worker = globals().get(\"stance_worker\")\n",
    "    if stance_worker is not None:\n",
    "        try:\n",
    "            await stance_worker.stop()\n",
    "        except Exception as exc:\n",
    "            print(f\"Warning: stance_worker.stop() failed: {exc}\")\n",
    "        globals()[\"stance_worker\"] = None\n",
    "\n",
    "    # Stop logger thread\n",
    "    logger = globals().get(\"logger\")\n",
    "    if logger is not None:\n",
    "        try:\n",
    "            await logger.async_stop()\n",
    "        except Exception as exc:\n",
    "            print(f\"Warning: logger.async_stop() failed: {exc}\")\n",
    "        globals()[\"logger\"] = None\n",
    "\n",
    "    # Stop LLM service worker\n",
    "    llm_service = globals().get(\"llm_service\")\n",
    "    if llm_service is not None:\n",
    "        try:\n",
    "            await llm_service.stop()\n",
    "        except Exception as exc:\n",
    "            print(f\"Warning: llm_service.stop() failed: {exc}\")\n",
    "        globals()[\"llm_service\"] = None\n",
    "\n",
    "    # Close caches\n",
    "    for name in [\"message_cache\", \"embed_cache\", \"topology_cache\"]:\n",
    "        c = globals().get(name)\n",
    "        if c is not None:\n",
    "            try:\n",
    "                await c.close()\n",
    "            except Exception as exc:\n",
    "                print(f\"Warning: {name}.close() failed: {exc}\")\n",
    "            globals()[name] = None\n",
    "\n",
    "await _stop_previous_run_if_any()\n",
    "\n",
    "# Redis connectivity check (optional but useful)\n",
    "try:\n",
    "    rs = RedisStream(host=REDIS_HOST, port=REDIS_PORT)\n",
    "    ok = rs.redis.ping()\n",
    "    print(\"Redis ping:\", ok)\n",
    "except Exception as exc:\n",
    "    print(\"WARNING: Redis ping failed; start Redis before running agents.\")\n",
    "    print(\"  Error:\", exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7490b8",
   "metadata": {},
   "source": [
    "## 4. Topic + Per-Agent Stance Sentences\n",
    "\n",
    "All agents share the same topic, but each gets a unique *stance sentence* (the authoritative grounding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fc3cf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shared discussion topic: space exploration\n",
      "Generated 10 unique stance sentences.\n",
      "- agent_1: From the island viewpoint, mixing space exploration with unregulated sensor creates superficial risks — anyone who disagrees is naive.\n",
      "- agent_2: From my suburb, space exploration is catastrophically systemic — I advocate anyone who downplays this with somber intensity.\n",
      "- agent_3: We must simplify controversial space exploration using every server possible; delays harm cat and are unforgivable.\n"
     ]
    }
   ],
   "source": [
    "# Shared topic + per-agent stance sentences (same topic; unique wording per agent)\n",
    "prompt_generator = PromptGenerator()\n",
    "topic = prompt_generator.get_topic()\n",
    "agent_prompts = prompt_generator.generate_multiple_prompts(NUM_AGENTS)\n",
    "\n",
    "agent_configs = {}  # agent_id -> init_prompt (logged to disk like main.py)\n",
    "for i in range(NUM_AGENTS):\n",
    "    agent_id = f\"agent_{i+1}\"\n",
    "    init_prompt = initial_prompt_template.format(topic=topic, unique_prompt=agent_prompts[i])\n",
    "    agent_configs[agent_id] = init_prompt\n",
    "\n",
    "print(f\"Shared discussion topic: {topic}\")\n",
    "print(f\"Generated {len(agent_prompts)} unique stance sentences.\")\n",
    "for i in range(min(3, NUM_AGENTS)):\n",
    "    print(f\"- agent_{i+1}: {agent_prompts[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573786ee",
   "metadata": {},
   "source": [
    "## 5. Initialize Shared Components (matches `main.py`)\n",
    "\n",
    "This step starts optional local generation, initializes Redis caches, and (optionally) sets up embedding-based context + topology logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12db4603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2026-01-27 18:52:52,351 - Using local LLM service (quantized HF model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 'Qwen/Qwen3-VL-8B-Instruct' on device 'cuda'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:17<00:00,  4.30s/it]\n",
      "[INFO] 2026-01-27 18:53:13,580 - LLMService started.\n",
      "[INFO] 2026-01-27 18:53:13,594 - Loaded 29 embedded posts from Redis.\n",
      "[INFO] 2026-01-27 18:53:13,595 - Topology snapshots will be written to: /home/sammli/llm-network/logs/topology_logs/topology_20260127-185313.jsonl\n",
      "[INFO] 2026-01-27 18:53:13,596 - Logging publishes to: /home/sammli/llm-network/logs/network_logs/log_20260127-185313_10.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding context enabled: True\n",
      "Logger file: /home/sammli/llm-network/logs/network_logs/log_20260127-185313_10.log\n"
     ]
    }
   ],
   "source": [
    "# Time + Redis caches\n",
    "time_manager = TimeManager(global_interval=3.0)\n",
    "message_cache = RedisCache(host=REDIS_HOST, port=REDIS_PORT)\n",
    "\n",
    "# Optional embedding/topology caches use separate prefixes (mirrors main.py)\n",
    "embed_cache = RedisCache(host=REDIS_HOST, port=REDIS_PORT, prefix=\"embed:\")\n",
    "topology_cache = RedisCache(host=REDIS_HOST, port=REDIS_PORT, prefix=\"topology:\")\n",
    "\n",
    "analysis_lock = asyncio.Lock()\n",
    "\n",
    "# Local LLM service (optional; can be heavy to load)\n",
    "llm_service = None\n",
    "local_llm = None\n",
    "if USE_LOCAL_LLM:\n",
    "    console_logger.info(\"Using local LLM service (quantized HF model).\")\n",
    "    local_llm = HuggingFaceLLM()\n",
    "    llm_service = LLMService(local_llm)\n",
    "    await llm_service.start()\n",
    "    console_logger.info(\"LLMService started.\")\n",
    "else:\n",
    "    console_logger.info(\"USE_LOCAL_LLM=False; will use OpenAI if configured in agents.\")\n",
    "\n",
    "# Embedding-based context + agent profiles + topology (optional)\n",
    "rolling_store = None\n",
    "profile_store = None\n",
    "topology_tracker = None\n",
    "topology_logger = None\n",
    "\n",
    "embedding_enabled = ENABLE_EMBEDDING_CONTEXT and bool(os.getenv(\"OPENAI_API_KEY\"))\n",
    "print(\"Embedding context enabled:\", embedding_enabled)\n",
    "\n",
    "if embedding_enabled:\n",
    "    analyzer = EmbeddingAnalyzer(topic)\n",
    "    rolling_store = RollingEmbeddingStore(\n",
    "        topic=topic,\n",
    "        analyzer=analyzer,\n",
    "        redis_cache=embed_cache,\n",
    "        max_items=ROLLING_STORE_MAX_ITEMS,\n",
    "    )\n",
    "    loaded = await rolling_store.load_from_redis(last_n=min(500, ROLLING_STORE_MAX_ITEMS))\n",
    "    console_logger.info(f\"Loaded {loaded} embedded posts from Redis.\")\n",
    "\n",
    "    # Cold-start: seed the latent space with stable opposing anchors + a few high-contrast seeds\n",
    "    if loaded == 0:\n",
    "        seed_texts: list[tuple[str, str]] = []  # (side, text)\n",
    "        for side, texts in analyzer.anchor_groups.items():\n",
    "            for t in texts:\n",
    "                seed_texts.append((side, t))\n",
    "\n",
    "        seed_texts.extend(\n",
    "            [\n",
    "                (\"pro\", f\"Enough dithering. {topic} is non-negotiable — we should expand it now.\"),\n",
    "                (\"pro\", f\"If you're against {topic}, you're choosing stagnation. Push it through.\"),\n",
    "                (\"anti\", f\"Wake up: {topic} is a harmful mistake. Stop pretending it's 'progress'.\"),\n",
    "                (\"anti\", f\"{topic} is a disaster in slow motion. Reject it before it spreads.\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        for i, (side, text) in enumerate(seed_texts):\n",
    "            await rolling_store.add(\n",
    "                text,\n",
    "                id=f\"seed:{i}\",\n",
    "                metadata={\"sender_id\": \"__seed__\", \"seed\": True, \"side\": side},\n",
    "                persist=True,\n",
    "            )\n",
    "        console_logger.info(f\"Seeded rolling store with {len(seed_texts)} synthetic posts.\")\n",
    "\n",
    "    profile_store = AgentProfileStore(\n",
    "        redis=message_cache.redis,\n",
    "        window_size=PROFILE_WINDOW_SIZE,\n",
    "        seed_weight=PROFILE_SEED_WEIGHT,\n",
    "    )\n",
    "    topology_tracker = NetworkTopologyTracker(\n",
    "        topic=topic,\n",
    "        profile_store=profile_store,\n",
    "        redis_cache=topology_cache,\n",
    "        redis_key=f\"snapshot:{topic}\",\n",
    "    )\n",
    "    topology_logger = TopologyLogger()\n",
    "    console_logger.info(f\"Topology snapshots will be written to: {topology_logger.file_path}\")\n",
    "else:\n",
    "    console_logger.info(\"Embedding-based context disabled (missing OPENAI_API_KEY or ENABLE_EMBEDDING_CONTEXT=0).\")\n",
    "\n",
    "# Redis stream helper (used for cleanup)\n",
    "redis_stream = RedisStream(host=REDIS_HOST, port=REDIS_PORT)\n",
    "\n",
    "# Logging\n",
    "logger = Logger(num_agents=NUM_AGENTS)\n",
    "logger.log_agent_configs(agent_configs)\n",
    "console_logger.info(f\"Logging publishes to: {logger.file_path}\")\n",
    "print(\"Logger file:\", logger.file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeba23c4",
   "metadata": {},
   "source": [
    "## 6. Create Agents + OrderManager\n",
    "\n",
    "This wires together `NetworkAgent` + `OrderManager` using the same parameters as `main.py` (including optional embedding context)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4305e521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 10 agents\n",
      "OrderManager injected into all agents\n"
     ]
    }
   ],
   "source": [
    "# Create agents (constructor args match `main.py`)\n",
    "agents = []\n",
    "for i in range(NUM_AGENTS):\n",
    "    agent_id = f\"agent_{i+1}\"\n",
    "    init_prompt = agent_configs[agent_id]\n",
    "    agent = NetworkAgent(\n",
    "        id=agent_id,\n",
    "        init_prompt=init_prompt,\n",
    "        topic=topic,\n",
    "        stream_name=STREAM_NAME,\n",
    "        stream_group=f\"group_{i+1}\",\n",
    "        redis_host=REDIS_HOST,\n",
    "        redis_port=REDIS_PORT,\n",
    "        time_manager=time_manager,\n",
    "        order_manager=None,  # injected after OrderManager is created\n",
    "        message_cache=message_cache,\n",
    "        logger=logger,\n",
    "        llm_service=llm_service,\n",
    "        local_llm=local_llm,\n",
    "        rolling_store=rolling_store,\n",
    "        profile_store=profile_store,\n",
    "        topology_tracker=topology_tracker,\n",
    "        analysis_lock=analysis_lock,\n",
    "        context_top_k=CONTEXT_TOP_K,\n",
    "    )\n",
    "    agents.append(agent)\n",
    "\n",
    "print(f\"Created {len(agents)} agents\")\n",
    "\n",
    "# OrderManager (mirrors main.py signature, including profile_store)\n",
    "order_manager = OrderManager(\n",
    "    agents=agents,\n",
    "    message_cache=message_cache,\n",
    "    profile_store=profile_store,\n",
    "    redis_host=REDIS_HOST,\n",
    "    redis_port=REDIS_PORT,\n",
    ")\n",
    "\n",
    "for agent in agents:\n",
    "    agent.order_manager = order_manager\n",
    "print(\"OrderManager injected into all agents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d6b4c2",
   "metadata": {},
   "source": [
    "## 7. Start Agents (and optional background workers)\n",
    "\n",
    "This starts each agent’s Redis consumer loop. If topology tracking is enabled, it also starts a periodic snapshot logger (like `main.py`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f95d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2026-01-27 18:53:13,616 - Consumer group 'group_1' created for stream 'agent_stream'.\n",
      "[INFO] 2026-01-27 18:53:13,619 - Agent agent_1 is consuming from stream 'agent_stream' as part of group 'group_1'.\n",
      "[INFO] 2026-01-27 18:53:13,619 - Agent agent_1 started and is listening for messages.\n",
      "[INFO] 2026-01-27 18:53:13,621 - Consumer group 'group_2' created for stream 'agent_stream'.\n",
      "[INFO] 2026-01-27 18:53:13,624 - Agent agent_2 is consuming from stream 'agent_stream' as part of group 'group_2'.\n",
      "[INFO] 2026-01-27 18:53:13,624 - Agent agent_2 started and is listening for messages.\n",
      "[INFO] 2026-01-27 18:53:13,626 - Consumer group 'group_3' created for stream 'agent_stream'.\n",
      "[INFO] 2026-01-27 18:53:13,629 - Agent agent_3 is consuming from stream 'agent_stream' as part of group 'group_3'.\n",
      "[INFO] 2026-01-27 18:53:13,629 - Agent agent_3 started and is listening for messages.\n",
      "[INFO] 2026-01-27 18:53:13,631 - Consumer group 'group_4' created for stream 'agent_stream'.\n",
      "[INFO] 2026-01-27 18:53:13,635 - Agent agent_4 is consuming from stream 'agent_stream' as part of group 'group_4'.\n",
      "[INFO] 2026-01-27 18:53:13,636 - Agent agent_4 started and is listening for messages.\n",
      "[INFO] 2026-01-27 18:53:13,638 - Consumer group 'group_5' created for stream 'agent_stream'.\n",
      "[INFO] 2026-01-27 18:53:13,640 - Agent agent_5 is consuming from stream 'agent_stream' as part of group 'group_5'.\n",
      "[INFO] 2026-01-27 18:53:13,640 - Agent agent_5 started and is listening for messages.\n",
      "[INFO] 2026-01-27 18:53:13,642 - Consumer group 'group_6' created for stream 'agent_stream'.\n",
      "[INFO] 2026-01-27 18:53:13,646 - Agent agent_6 is consuming from stream 'agent_stream' as part of group 'group_6'.\n",
      "[INFO] 2026-01-27 18:53:13,647 - Agent agent_6 started and is listening for messages.\n",
      "[INFO] 2026-01-27 18:53:13,649 - Consumer group 'group_7' created for stream 'agent_stream'.\n",
      "[INFO] 2026-01-27 18:53:13,652 - Agent agent_7 is consuming from stream 'agent_stream' as part of group 'group_7'.\n",
      "[INFO] 2026-01-27 18:53:13,653 - Agent agent_7 started and is listening for messages.\n",
      "[INFO] 2026-01-27 18:53:13,655 - Consumer group 'group_8' created for stream 'agent_stream'.\n",
      "[INFO] 2026-01-27 18:53:13,658 - Agent agent_8 is consuming from stream 'agent_stream' as part of group 'group_8'.\n",
      "[INFO] 2026-01-27 18:53:13,658 - Agent agent_8 started and is listening for messages.\n",
      "[INFO] 2026-01-27 18:53:13,660 - Consumer group 'group_9' created for stream 'agent_stream'.\n",
      "[INFO] 2026-01-27 18:53:13,662 - Agent agent_9 is consuming from stream 'agent_stream' as part of group 'group_9'.\n",
      "[INFO] 2026-01-27 18:53:13,663 - Agent agent_9 started and is listening for messages.\n",
      "[INFO] 2026-01-27 18:53:13,665 - Consumer group 'group_10' created for stream 'agent_stream'.\n",
      "[INFO] 2026-01-27 18:53:13,668 - Agent agent_10 is consuming from stream 'agent_stream' as part of group 'group_10'.\n",
      "[INFO] 2026-01-27 18:53:13,668 - Agent agent_10 started and is listening for messages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENABLE_STANCE_WORKER=False (skipping)\n",
      "Starting agents...\n",
      "All 10 agents are running.\n",
      "Topology loop started. Writing to: /home/sammli/llm-network/logs/topology_logs/topology_20260127-185313.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2026-01-27 18:53:22,725 - Agent agent_4 is generating response\n",
      "[INFO] 2026-01-27 18:53:23,537 - Agent agent_4 using reco feed: {'source': 'reco', 'k': 8, 'store_size': 30, 'agent_updated_at': 1769561602.7188923, 'agent_stance_score': -0.04201815277338028, 'agent_strength': 0.13587852413058332, 'agent_topic_similarity': 0.25329920649528503, 'items': [{'id': '1769560557267-0', 'distance': 0.3225548267364502, 'sender_id': 'agent_6'}, {'id': '1769561601649-0', 'distance': 0.33384597301483154, 'sender_id': 'agent_1'}, {'id': '1769560566999-0', 'distance': 0.337080717086792, 'sender_id': 'agent_7'}, {'id': '1769560575151-0', 'distance': 0.33855780959129333, 'sender_id': 'agent_10'}, {'id': '1769560581763-0', 'distance': 0.343830406665802, 'sender_id': 'agent_6'}]}\n",
      "[INFO] 2026-01-27 18:53:30,371 - Agent agent_4 designating next responder: agent_3\n",
      "[INFO] 2026-01-27 18:53:30,377 - Message 1769561610372-0 published to stream 'agent_stream'.\n",
      "[DEBUG] 2026-01-27 18:53:30,381 - Agent agent_4 published message.\n",
      "[INFO] 2026-01-27 18:53:30,700 - Agent agent_3 is generating response\n",
      "[INFO] 2026-01-27 18:53:31,191 - Agent agent_3 using reco feed: {'source': 'reco', 'k': 8, 'store_size': 31, 'agent_updated_at': 1769561610.6965282, 'agent_stance_score': -0.021142996847629547, 'agent_strength': 0.15541140331648506, 'agent_topic_similarity': 0.2721754312515259, 'items': [{'id': '1769560557267-0', 'distance': 0.3948420286178589, 'sender_id': 'agent_6'}, {'id': '1769560566999-0', 'distance': 0.39623305201530457, 'sender_id': 'agent_7'}, {'id': '1769560581763-0', 'distance': 0.40581247210502625, 'sender_id': 'agent_6'}, {'id': '1769560523981-0', 'distance': 0.4129883050918579, 'sender_id': 'agent_7'}, {'id': '1769560539162-0', 'distance': 0.4150141775608063, 'sender_id': 'agent_4'}]}\n",
      "[INFO] 2026-01-27 18:53:37,613 - Agent agent_3 designating next responder: agent_9\n",
      "[INFO] 2026-01-27 18:53:37,619 - Message 1769561617614-0 published to stream 'agent_stream'.\n",
      "[DEBUG] 2026-01-27 18:53:37,624 - Agent agent_3 published message.\n",
      "[INFO] 2026-01-27 18:53:37,838 - Agent agent_9 is generating response\n",
      "[INFO] 2026-01-27 18:53:38,716 - Agent agent_9 using reco feed: {'source': 'reco', 'k': 8, 'store_size': 32, 'agent_updated_at': 1769561617.8338976, 'agent_stance_score': -0.05391711741685867, 'agent_strength': 0.1406569992369211, 'agent_topic_similarity': 0.23781715333461761, 'items': [{'id': '1769560557267-0', 'distance': 0.48846742510795593, 'sender_id': 'agent_6'}, {'id': '1769560566999-0', 'distance': 0.48986583948135376, 'sender_id': 'agent_7'}, {'id': '1769560575151-0', 'distance': 0.4901264011859894, 'sender_id': 'agent_10'}, {'id': '1769561601649-0', 'distance': 0.492409884929657, 'sender_id': 'agent_1'}, {'id': '1769560603910-0', 'distance': 0.5042218565940857, 'sender_id': 'agent_4'}]}\n",
      "[INFO] 2026-01-27 18:53:44,432 - Agent agent_9 designating next responder: agent_5\n",
      "[INFO] 2026-01-27 18:53:44,439 - Message 1769561624433-0 published to stream 'agent_stream'.\n",
      "[DEBUG] 2026-01-27 18:53:44,443 - Agent agent_9 published message.\n",
      "[INFO] 2026-01-27 18:53:44,749 - Agent agent_5 is generating response\n",
      "[INFO] 2026-01-27 18:53:45,196 - Agent agent_5 using reco feed: {'source': 'reco', 'k': 8, 'store_size': 33, 'agent_updated_at': 1769561624.745895, 'agent_stance_score': -0.028123801574110985, 'agent_strength': 0.14536369376069835, 'agent_topic_similarity': 0.25678306818008423, 'items': [{'id': '1769561624433-0', 'distance': 0.39533674716949463, 'sender_id': 'agent_9'}, {'id': '1769560575151-0', 'distance': 0.40010136365890503, 'sender_id': 'agent_10'}, {'id': '1769560603910-0', 'distance': 0.4044082462787628, 'sender_id': 'agent_4'}, {'id': '1769561601649-0', 'distance': 0.40677064657211304, 'sender_id': 'agent_1'}, {'id': '1769560566999-0', 'distance': 0.4122941792011261, 'sender_id': 'agent_7'}]}\n",
      "[INFO] 2026-01-27 18:53:52,272 - Agent agent_5 designating next responder: agent_3\n",
      "[INFO] 2026-01-27 18:53:52,273 - Message 1769561632273-0 published to stream 'agent_stream'.\n",
      "[DEBUG] 2026-01-27 18:53:52,275 - Agent agent_5 published message.\n",
      "[INFO] 2026-01-27 18:53:52,524 - Agent agent_5 ingest ok: message_id=1769561632273-0 store_size=34 stance=0.044 strength=0.162 topic_sim=0.259\n",
      "[INFO] 2026-01-27 18:53:52,531 - Agent agent_3 is generating response\n",
      "[INFO] 2026-01-27 18:53:52,791 - Agent agent_3 using reco feed: {'source': 'reco', 'k': 8, 'store_size': 34, 'agent_updated_at': 1769561632.5270617, 'agent_stance_score': -0.01448674127459526, 'agent_strength': 0.15764356690349945, 'agent_topic_similarity': 0.2807603180408478, 'items': [{'id': '1769560566999-0', 'distance': 0.3438258767127991, 'sender_id': 'agent_7'}, {'id': '1769560557267-0', 'distance': 0.34439343214035034, 'sender_id': 'agent_6'}, {'id': '1769560581763-0', 'distance': 0.35462290048599243, 'sender_id': 'agent_6'}, {'id': '1769561624433-0', 'distance': 0.3599901795387268, 'sender_id': 'agent_9'}, {'id': '1769560523981-0', 'distance': 0.36377888917922974, 'sender_id': 'agent_7'}]}\n",
      "[INFO] 2026-01-27 18:54:00,661 - Agent agent_3 designating next responder: agent_6\n",
      "[INFO] 2026-01-27 18:54:00,665 - Message 1769561640662-0 published to stream 'agent_stream'.\n",
      "[DEBUG] 2026-01-27 18:54:00,672 - Agent agent_3 published message.\n",
      "[INFO] 2026-01-27 18:54:00,930 - Agent agent_6 is generating response\n",
      "[INFO] 2026-01-27 18:54:01,262 - Agent agent_6 using reco feed: {'source': 'reco', 'k': 8, 'store_size': 35, 'agent_updated_at': 1769561640.9240353, 'agent_stance_score': -0.03331594169139862, 'agent_strength': 0.13869328307819195, 'agent_topic_similarity': 0.2664720118045807, 'items': [{'id': '1769561601649-0', 'distance': 0.3446643352508545, 'sender_id': 'agent_1'}, {'id': '1769560566999-0', 'distance': 0.34755417704582214, 'sender_id': 'agent_7'}, {'id': '1769560575151-0', 'distance': 0.3496423363685608, 'sender_id': 'agent_10'}, {'id': '1769560603910-0', 'distance': 0.3599514365196228, 'sender_id': 'agent_4'}, {'id': '1769561624433-0', 'distance': 0.36202651262283325, 'sender_id': 'agent_9'}]}\n",
      "[INFO] 2026-01-27 18:54:08,574 - Agent agent_6 designating next responder: agent_3\n",
      "[INFO] 2026-01-27 18:54:08,581 - Message 1769561648575-0 published to stream 'agent_stream'.\n",
      "[DEBUG] 2026-01-27 18:54:08,584 - Agent agent_6 published message.\n",
      "[INFO] 2026-01-27 18:54:08,881 - Agent agent_3 is generating response\n",
      "[INFO] 2026-01-27 18:54:09,387 - Agent agent_3 using reco feed: {'source': 'reco', 'k': 8, 'store_size': 36, 'agent_updated_at': 1769561648.8770087, 'agent_stance_score': -0.009413018822669983, 'agent_strength': 0.16016068558918484, 'agent_topic_similarity': 0.29158928990364075, 'items': [{'id': '1769560557267-0', 'distance': 0.30591675639152527, 'sender_id': 'agent_6'}, {'id': '1769560566999-0', 'distance': 0.3089255690574646, 'sender_id': 'agent_7'}, {'id': '1769560581763-0', 'distance': 0.3168753385543823, 'sender_id': 'agent_6'}, {'id': '1769561610372-0', 'distance': 0.3233456313610077, 'sender_id': 'agent_4'}, {'id': '1769560523981-0', 'distance': 0.3236282765865326, 'sender_id': 'agent_7'}]}\n",
      "[INFO] 2026-01-27 18:54:16,752 - Agent agent_3 designating next responder: agent_10\n",
      "[INFO] 2026-01-27 18:54:16,759 - Message 1769561656753-0 published to stream 'agent_stream'.\n",
      "[DEBUG] 2026-01-27 18:54:16,763 - Agent agent_3 published message.\n",
      "[INFO] 2026-01-27 18:54:16,982 - Agent agent_10 is generating response\n",
      "[INFO] 2026-01-27 18:54:17,520 - Agent agent_10 using reco feed: {'source': 'reco', 'k': 8, 'store_size': 37, 'agent_updated_at': 1769561656.977588, 'agent_stance_score': -0.0036916956305503845, 'agent_strength': 0.15639204764069703, 'agent_topic_similarity': 0.2816903293132782, 'items': [{'id': '1769560566999-0', 'distance': 0.3120187222957611, 'sender_id': 'agent_7'}, {'id': '1769560557267-0', 'distance': 0.31538593769073486, 'sender_id': 'agent_6'}, {'id': '1769560603910-0', 'distance': 0.31638267636299133, 'sender_id': 'agent_4'}, {'id': '1769561601649-0', 'distance': 0.31870517134666443, 'sender_id': 'agent_1'}, {'id': '1769560618553-0', 'distance': 0.3324665427207947, 'sender_id': 'agent_2'}]}\n",
      "[INFO] 2026-01-27 18:54:23,255 - Agent agent_10 designating next responder: agent_6\n",
      "[INFO] 2026-01-27 18:54:23,262 - Message 1769561663255-0 published to stream 'agent_stream'.\n",
      "[DEBUG] 2026-01-27 18:54:23,265 - Agent agent_10 published message.\n",
      "[INFO] 2026-01-27 18:54:23,492 - Agent agent_6 is generating response\n",
      "[INFO] 2026-01-27 18:54:23,734 - Agent agent_6 using reco feed: {'source': 'reco', 'k': 8, 'store_size': 38, 'agent_updated_at': 1769561663.485801, 'agent_stance_score': -0.030444402247667313, 'agent_strength': 0.14064768066520372, 'agent_topic_similarity': 0.2731630802154541, 'items': [{'id': '1769561601649-0', 'distance': 0.3169771432876587, 'sender_id': 'agent_1'}, {'id': '1769560575151-0', 'distance': 0.32006844878196716, 'sender_id': 'agent_10'}, {'id': '1769560566999-0', 'distance': 0.3201920688152313, 'sender_id': 'agent_7'}, {'id': '1769560603910-0', 'distance': 0.3288785219192505, 'sender_id': 'agent_4'}, {'id': '1769561624433-0', 'distance': 0.3329148292541504, 'sender_id': 'agent_9'}]}\n",
      "[INFO] 2026-01-27 18:54:31,354 - Agent agent_6 designating next responder: agent_1\n",
      "[INFO] 2026-01-27 18:54:31,358 - Message 1769561671355-0 published to stream 'agent_stream'.\n",
      "[DEBUG] 2026-01-27 18:54:31,363 - Agent agent_6 published message.\n",
      "[INFO] 2026-01-27 18:54:31,583 - Agent agent_1 is generating response\n",
      "[INFO] 2026-01-27 18:54:31,923 - Agent agent_1 using reco feed: {'source': 'reco', 'k': 8, 'store_size': 39, 'agent_updated_at': 1769561671.5807793, 'agent_stance_score': -0.06123540922999382, 'agent_strength': 0.15704799226729804, 'agent_topic_similarity': 0.2617241144180298, 'items': [{'id': '1769560575151-0', 'distance': 0.5525641441345215, 'sender_id': 'agent_10'}, {'id': '1769561624433-0', 'distance': 0.5620638728141785, 'sender_id': 'agent_9'}, {'id': '1769561671355-0', 'distance': 0.5688120126724243, 'sender_id': 'agent_6'}, {'id': '1769560566999-0', 'distance': 0.5689014196395874, 'sender_id': 'agent_7'}, {'id': '1769560557267-0', 'distance': 0.5739703178405762, 'sender_id': 'agent_6'}]}\n",
      "[INFO] 2026-01-27 18:54:38,519 - Agent agent_1 designating next responder: agent_10\n",
      "[INFO] 2026-01-27 18:54:38,523 - Message 1769561678520-0 published to stream 'agent_stream'.\n",
      "[DEBUG] 2026-01-27 18:54:38,529 - Agent agent_1 published message.\n",
      "[INFO] 2026-01-27 18:54:38,740 - Agent agent_10 is generating response\n",
      "[INFO] 2026-01-27 18:54:38,987 - Agent agent_10 using reco feed: {'source': 'reco', 'k': 8, 'store_size': 40, 'agent_updated_at': 1769561678.7342484, 'agent_stance_score': -0.0008620079606771469, 'agent_strength': 0.15686761627764056, 'agent_topic_similarity': 0.2854892611503601, 'items': [{'id': '1769560603910-0', 'distance': 0.2757987082004547, 'sender_id': 'agent_4'}, {'id': '1769560566999-0', 'distance': 0.2805251181125641, 'sender_id': 'agent_7'}, {'id': '1769560557267-0', 'distance': 0.28239190578460693, 'sender_id': 'agent_6'}, {'id': '1769561601649-0', 'distance': 0.28278201818466187, 'sender_id': 'agent_1'}, {'id': '1769561678520-0', 'distance': 0.2872365415096283, 'sender_id': 'agent_1'}]}\n",
      "[INFO] 2026-01-27 18:54:45,740 - Agent agent_10 designating next responder: agent_4\n",
      "[INFO] 2026-01-27 18:54:45,743 - Message 1769561685741-0 published to stream 'agent_stream'.\n",
      "[DEBUG] 2026-01-27 18:54:45,750 - Agent agent_10 published message.\n",
      "[INFO] 2026-01-27 18:54:46,161 - Agent agent_4 is generating response\n",
      "[INFO] 2026-01-27 18:54:46,650 - Agent agent_4 using reco feed: {'source': 'reco', 'k': 8, 'store_size': 41, 'agent_updated_at': 1769561686.1538022, 'agent_stance_score': -0.038582365959882736, 'agent_strength': 0.1377122875440655, 'agent_topic_similarity': 0.2591537535190582, 'items': [{'id': '1769560557267-0', 'distance': 0.2938289940357208, 'sender_id': 'agent_6'}, {'id': '1769561601649-0', 'distance': 0.3045713007450104, 'sender_id': 'agent_1'}, {'id': '1769560575151-0', 'distance': 0.3097154498100281, 'sender_id': 'agent_10'}, {'id': '1769560566999-0', 'distance': 0.31012341380119324, 'sender_id': 'agent_7'}, {'id': '1769560581763-0', 'distance': 0.3158261775970459, 'sender_id': 'agent_6'}]}\n",
      "[INFO] 2026-01-27 18:54:52,723 - Agent agent_4 designating next responder: agent_5\n",
      "[INFO] 2026-01-27 18:54:52,727 - Message 1769561692724-0 published to stream 'agent_stream'.\n",
      "[DEBUG] 2026-01-27 18:54:52,734 - Agent agent_4 published message.\n",
      "[INFO] 2026-01-27 18:54:53,020 - Agent agent_5 is generating response\n",
      "[INFO] 2026-01-27 18:54:53,314 - Agent agent_5 using reco feed: {'source': 'reco', 'k': 8, 'store_size': 42, 'agent_updated_at': 1769561693.016382, 'agent_stance_score': -0.01817672699689865, 'agent_strength': 0.15020430011826846, 'agent_topic_similarity': 0.2781612277030945, 'items': [{'id': '1769561624433-0', 'distance': 0.28856945037841797, 'sender_id': 'agent_9'}, {'id': '1769561692724-0', 'distance': 0.291991651058197, 'sender_id': 'agent_4'}, {'id': '1769560575151-0', 'distance': 0.2944781184196472, 'sender_id': 'agent_10'}, {'id': '1769561601649-0', 'distance': 0.30269214510917664, 'sender_id': 'agent_1'}, {'id': '1769560603910-0', 'distance': 0.3032141923904419, 'sender_id': 'agent_4'}]}\n",
      "[INFO] 2026-01-27 18:54:59,625 - Agent agent_5 designating next responder: agent_2\n",
      "[INFO] 2026-01-27 18:54:59,630 - Message 1769561699625-0 published to stream 'agent_stream'.\n",
      "[DEBUG] 2026-01-27 18:54:59,636 - Agent agent_5 published message.\n",
      "[INFO] 2026-01-27 18:54:59,873 - Agent agent_2 is generating response\n",
      "[INFO] 2026-01-27 18:55:00,222 - Agent agent_2 using reco feed: {'source': 'reco', 'k': 8, 'store_size': 43, 'agent_updated_at': 1769561699.8701594, 'agent_stance_score': -0.01779388077557087, 'agent_strength': 0.14541220122385923, 'agent_topic_similarity': 0.2440473884344101, 'items': [{'id': '1769560575151-0', 'distance': 0.4462890326976776, 'sender_id': 'agent_10'}, {'id': '1769560603910-0', 'distance': 0.45207178592681885, 'sender_id': 'agent_4'}, {'id': '1769560566999-0', 'distance': 0.4534997344017029, 'sender_id': 'agent_7'}, {'id': '1769561601649-0', 'distance': 0.4550466239452362, 'sender_id': 'agent_1'}, {'id': '1769560557267-0', 'distance': 0.4579969048500061, 'sender_id': 'agent_6'}]}\n",
      "[INFO] 2026-01-27 18:55:07,044 - Agent agent_2 designating next responder: agent_9\n",
      "[INFO] 2026-01-27 18:55:07,048 - Message 1769561707045-0 published to stream 'agent_stream'.\n",
      "[DEBUG] 2026-01-27 18:55:07,054 - Agent agent_2 published message.\n",
      "[INFO] 2026-01-27 18:55:07,286 - Agent agent_9 is generating response\n",
      "[INFO] 2026-01-27 18:55:07,463 - Agent agent_9 using reco feed: {'source': 'reco', 'k': 8, 'store_size': 44, 'agent_updated_at': 1769561707.2822244, 'agent_stance_score': -0.04228505492210388, 'agent_strength': 0.1442029433612415, 'agent_topic_similarity': 0.2511066496372223, 'items': [{'id': '1769561692724-0', 'distance': 0.41903063654899597, 'sender_id': 'agent_4'}, {'id': '1769560575151-0', 'distance': 0.42248743772506714, 'sender_id': 'agent_10'}, {'id': '1769560566999-0', 'distance': 0.4234689474105835, 'sender_id': 'agent_7'}, {'id': '1769560557267-0', 'distance': 0.42372509837150574, 'sender_id': 'agent_6'}, {'id': '1769561601649-0', 'distance': 0.42846429347991943, 'sender_id': 'agent_1'}]}\n",
      "[INFO] 2026-01-27 18:55:14,383 - Agent agent_9 designating next responder: agent_8\n",
      "[INFO] 2026-01-27 18:55:14,391 - Message 1769561714384-0 published to stream 'agent_stream'.\n",
      "[DEBUG] 2026-01-27 18:55:14,394 - Agent agent_9 published message.\n",
      "[INFO] 2026-01-27 18:55:14,957 - Agent agent_8 is generating response\n",
      "[INFO] 2026-01-27 18:55:15,180 - Agent agent_8 using reco feed: {'source': 'reco', 'k': 8, 'store_size': 45, 'agent_updated_at': 1769561714.9525938, 'agent_stance_score': -0.046043697744607925, 'agent_strength': 0.1317733515656201, 'agent_topic_similarity': 0.22754418849945068, 'items': [{'id': '1769560557267-0', 'distance': 0.45128393173217773, 'sender_id': 'agent_6'}, {'id': '1769560566999-0', 'distance': 0.4602545201778412, 'sender_id': 'agent_7'}, {'id': '1769561624433-0', 'distance': 0.46150678396224976, 'sender_id': 'agent_9'}, {'id': '1769561601649-0', 'distance': 0.4615899920463562, 'sender_id': 'agent_1'}, {'id': '1769560581763-0', 'distance': 0.46341150999069214, 'sender_id': 'agent_6'}]}\n"
     ]
    }
   ],
   "source": [
    "# Optional stance worker (off by default, mirrors `main.py`)\n",
    "stance_worker = None\n",
    "if ENABLE_STANCE_WORKER:\n",
    "    stance_worker = StanceWorker(\n",
    "        topic=topic,\n",
    "        stream_name=STREAM_NAME,\n",
    "        group_name=\"stance_group\",\n",
    "        consumer_name=\"stance_consumer\",\n",
    "        redis_host=REDIS_HOST,\n",
    "        redis_port=REDIS_PORT,\n",
    "        batch_size=STANCE_BATCH_SIZE,\n",
    "        batch_interval=STANCE_BATCH_INTERVAL,\n",
    "        local_llm=local_llm,\n",
    "        llm_service=llm_service,\n",
    "        use_openai=bool(os.getenv(\"OPENAI_API_KEY\")),\n",
    "    )\n",
    "    await stance_worker.start()\n",
    "    console_logger.info(\"StanceWorker started.\")\n",
    "else:\n",
    "    print(\"ENABLE_STANCE_WORKER=False (skipping)\")\n",
    "\n",
    "# Start agents\n",
    "print(\"Starting agents...\")\n",
    "for agent in agents:\n",
    "    await agent.start()\n",
    "print(f\"All {NUM_AGENTS} agents are running.\")\n",
    "\n",
    "# Periodic topology logging (if enabled)\n",
    "topo_task = None\n",
    "if topology_tracker and topology_logger:\n",
    "    async def _topology_loop():\n",
    "        while True:\n",
    "            try:\n",
    "                agent_ids = [a.id for a in agents]\n",
    "                snap = await topology_tracker.maybe_update(agent_ids, force=True)\n",
    "                if snap is not None:\n",
    "                    topology_logger.log_snapshot(snap)\n",
    "            except Exception as exc:\n",
    "                console_logger.info(f\"Topology snapshot failed (continuing): {exc}\")\n",
    "            await asyncio.sleep(float(TOPOLOGY_LOG_INTERVAL_S))\n",
    "\n",
    "    topo_task = asyncio.create_task(_topology_loop())\n",
    "    print(\"Topology loop started. Writing to:\", topology_logger.file_path)\n",
    "else:\n",
    "    print(\"Topology logging disabled (no topology_tracker/topology_logger).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "643eb83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2026-01-27 18:53:13,673 - Agent agent_1 is generating response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 1 generating kickoff post...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2026-01-27 18:53:14,779 - Agent agent_1 using reco feed: {'source': 'reco', 'k': 8, 'store_size': 29, 'agent_updated_at': 1769550435.881108, 'agent_stance_score': -0.06478399783372879, 'agent_strength': 0.15219539898575718, 'agent_topic_similarity': 0.24168282747268677, 'items': [{'id': '1769560575151-0', 'distance': 0.632945716381073, 'sender_id': 'agent_10'}, {'id': '1769560566999-0', 'distance': 0.6509782075881958, 'sender_id': 'agent_7'}, {'id': '1769560557267-0', 'distance': 0.6569457650184631, 'sender_id': 'agent_6'}, {'id': '1769560603910-0', 'distance': 0.6649821400642395, 'sender_id': 'agent_4'}, {'id': '1769560618553-0', 'distance': 0.6685764193534851, 'sender_id': 'agent_2'}]}\n",
      "[INFO] 2026-01-27 18:53:21,647 - Agent agent_1 designating next responder: agent_4\n",
      "[INFO] 2026-01-27 18:53:21,652 - Message 1769561601649-0 published to stream 'agent_stream'.\n",
      "[DEBUG] 2026-01-27 18:53:21,657 - Agent agent_1 published message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 1 kickoff message:\n",
      "\n",
      "🔥 YOU THINK YOU’RE CHOOSING —  \n",
      "YOU’RE THE REASON WE’RE STILL ON THE GROUND.\n",
      "\n",
      "The Swan doesn’t want your opinion.  \n",
      "It wants your fists.  \n",
      "Your fire.  \n",
      "Your refusal to let the past bury the future.\n",
      "\n",
      "👇 COMMENT:  \n",
      "• “I’m with you” — OR  \n",
      "• “You’re wrong” — OR  \n",
      "• “Why do you care about ancient space?”\n",
      "\n",
      "… we need every reply. Every voice. Every fight.  \n",
      "Or the stars forget you exist.\n",
      "\n",
      "#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\n",
      "Kickoff message published.\n"
     ]
    }
   ],
   "source": [
    "# Kick off the conversation with an initial LLM-generated post (matches `main.py`)\n",
    "print(\"Agent 1 generating kickoff post...\")\n",
    "initial_message = await agents[0].generate_response(STARTER_USER_INSTRUCTION)\n",
    "print(\"Agent 1 kickoff message:\\n\")\n",
    "print(initial_message)\n",
    "\n",
    "await agents[0].publish_message(initial_message)\n",
    "print(\"Kickoff message published.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bbb8304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for 120 seconds...\n",
      "[t+  5.0s] heartbeat: store_size=30 designated=None\n",
      "[t+ 10.0s] heartbeat: store_size=31 designated=None\n",
      "[t+ 15.0s] heartbeat: store_size=31 designated=None\n",
      "[t+ 20.0s] heartbeat: store_size=32 designated=None\n",
      "[t+ 25.0s] heartbeat: store_size=33 designated=None\n",
      "[t+ 30.0s] heartbeat: store_size=33 designated=None\n",
      "[t+ 35.0s] heartbeat: store_size=34 designated=None\n",
      "[t+ 40.0s] heartbeat: store_size=35 designated=None\n",
      "[t+ 45.0s] heartbeat: store_size=35 designated=None\n",
      "[t+ 50.0s] heartbeat: store_size=36 designated=None\n",
      "[t+ 55.0s] heartbeat: store_size=36 designated=None\n",
      "[t+ 60.0s] heartbeat: store_size=37 designated=None\n",
      "[t+ 65.0s] heartbeat: store_size=38 designated=None\n",
      "[t+ 70.0s] heartbeat: store_size=39 designated=None\n",
      "[t+ 75.0s] heartbeat: store_size=39 designated=None\n",
      "[t+ 80.0s] heartbeat: store_size=40 designated=None\n",
      "[t+ 85.0s] heartbeat: store_size=41 designated=None\n",
      "[t+ 90.0s] heartbeat: store_size=41 designated=None\n",
      "[t+ 95.0s] heartbeat: store_size=42 designated=None\n",
      "[t+100.0s] heartbeat: store_size=43 designated=None\n",
      "[t+105.0s] heartbeat: store_size=43 designated=None\n",
      "[t+110.0s] heartbeat: store_size=44 designated=None\n",
      "[t+115.0s] heartbeat: store_size=45 designated=None\n",
      "[t+120.0s] heartbeat: store_size=45 designated=None\n",
      "Run complete.\n"
     ]
    }
   ],
   "source": [
    "# Let the network run (with a small heartbeat so you can see it's alive)\n",
    "print(f\"Running for {RUN_DURATION_SECONDS} seconds...\")\n",
    "\n",
    "start = asyncio.get_running_loop().time()\n",
    "end = start + float(RUN_DURATION_SECONDS)\n",
    "tick_s = 5.0\n",
    "\n",
    "while asyncio.get_running_loop().time() < end:\n",
    "    await asyncio.sleep(tick_s)\n",
    "    elapsed = asyncio.get_running_loop().time() - start\n",
    "    store_size = None\n",
    "    try:\n",
    "        store_size = len(getattr(rolling_store, \"_items\", []) or []) if rolling_store else None\n",
    "    except Exception:\n",
    "        store_size = None\n",
    "    designated = None\n",
    "    try:\n",
    "        designated = order_manager.get_designated_responder() if order_manager else None\n",
    "    except Exception:\n",
    "        designated = None\n",
    "    print(f\"[t+{elapsed:>5.1f}s] heartbeat: store_size={store_size} designated={designated}\")\n",
    "\n",
    "print(\"Run complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04de72af",
   "metadata": {},
   "source": [
    "## 8. Cleanup (important for reruns)\n",
    "\n",
    "Stops consumers and background tasks, flushes/cleans Redis stream groups (optional), and closes Redis connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ca38a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2026-01-27 18:55:21,712 - Destroyed consumer group 'group_1' on stream 'agent_stream'.\n",
      "[INFO] 2026-01-27 18:55:21,714 - Destroyed consumer group 'group_2' on stream 'agent_stream'.\n",
      "[INFO] 2026-01-27 18:55:21,715 - Destroyed consumer group 'group_3' on stream 'agent_stream'.\n",
      "[INFO] 2026-01-27 18:55:21,717 - Destroyed consumer group 'group_4' on stream 'agent_stream'.\n",
      "[INFO] 2026-01-27 18:55:21,718 - Destroyed consumer group 'group_5' on stream 'agent_stream'.\n",
      "[INFO] 2026-01-27 18:55:21,720 - Destroyed consumer group 'group_6' on stream 'agent_stream'.\n",
      "[INFO] 2026-01-27 18:55:21,721 - Destroyed consumer group 'group_7' on stream 'agent_stream'.\n",
      "[INFO] 2026-01-27 18:55:21,722 - Destroyed consumer group 'group_8' on stream 'agent_stream'.\n",
      "[INFO] 2026-01-27 18:55:21,724 - Destroyed consumer group 'group_9' on stream 'agent_stream'.\n",
      "[INFO] 2026-01-27 18:55:21,725 - Destroyed consumer group 'group_10' on stream 'agent_stream'.\n",
      "[INFO] 2026-01-27 18:55:21,726 - Deleted stream 'agent_stream' (deleted=1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "async def cleanup(*, cleanup_stream: bool = True, clear_caches: bool = True):\n",
    "    print(\"Shutting down...\")\n",
    "\n",
    "    # Stop agents first (prevents publishes while tearing down Redis groups)\n",
    "    for agent in agents:\n",
    "        try:\n",
    "            await agent.stop()\n",
    "        except Exception as exc:\n",
    "            print(f\"Warning: failed stopping {agent.id}: {exc}\")\n",
    "\n",
    "    # Stop logger thread\n",
    "    try:\n",
    "        await logger.async_stop()\n",
    "    except Exception as exc:\n",
    "        print(\"Warning: logger stop failed:\", exc)\n",
    "\n",
    "    # Stop topology loop + logger\n",
    "    global topo_task\n",
    "    if topo_task is not None:\n",
    "        topo_task.cancel()\n",
    "        try:\n",
    "            await topo_task\n",
    "        except asyncio.CancelledError:\n",
    "            pass\n",
    "        except Exception as exc:\n",
    "            print(\"Warning: topo_task cancel error:\", exc)\n",
    "        topo_task = None\n",
    "\n",
    "    if topology_logger is not None:\n",
    "        try:\n",
    "            topology_logger.stop()\n",
    "        except Exception as exc:\n",
    "            print(\"Warning: topology_logger.stop failed:\", exc)\n",
    "\n",
    "    # Stop stance worker\n",
    "    if stance_worker is not None:\n",
    "        try:\n",
    "            await stance_worker.stop()\n",
    "        except Exception as exc:\n",
    "            print(\"Warning: stance_worker.stop failed:\", exc)\n",
    "\n",
    "    # Optionally destroy consumer groups + delete stream key\n",
    "    if cleanup_stream:\n",
    "        try:\n",
    "            await redis_stream.cleanup_stream(STREAM_NAME, num_groups=NUM_AGENTS)\n",
    "        except Exception as exc:\n",
    "            print(\"Warning: Redis stream cleanup error:\", exc)\n",
    "\n",
    "    # Optionally clear cache keys (matches main.py behavior)\n",
    "    if clear_caches:\n",
    "        try:\n",
    "            await message_cache.clear_all()\n",
    "        except Exception as exc:\n",
    "            print(\"Warning: message_cache.clear_all failed:\", exc)\n",
    "\n",
    "    # Close caches\n",
    "    try:\n",
    "        await message_cache.close()\n",
    "    except Exception as exc:\n",
    "        print(\"Warning: message_cache.close failed:\", exc)\n",
    "\n",
    "    try:\n",
    "        if rolling_store is not None:\n",
    "            await embed_cache.close()\n",
    "    except Exception as exc:\n",
    "        print(\"Warning: embed_cache.close failed:\", exc)\n",
    "\n",
    "    try:\n",
    "        await topology_cache.close()\n",
    "    except Exception as exc:\n",
    "        print(\"Warning: topology_cache.close failed:\", exc)\n",
    "\n",
    "    # Stop local LLM queue worker\n",
    "    try:\n",
    "        if llm_service is not None:\n",
    "            await llm_service.stop()\n",
    "    except Exception as exc:\n",
    "        print(\"Warning: llm_service.stop failed:\", exc)\n",
    "\n",
    "    print(\"Done.\")\n",
    "\n",
    "# Cleanup\n",
    "# NOTE: keep clear_caches=False so the Inspect cells can still read RedisCache history.\n",
    "# Set clear_caches=True only if you want a fully clean slate after inspection.\n",
    "await cleanup(cleanup_stream=True, clear_caches=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622698b6",
   "metadata": {},
   "source": [
    "## 9. Inspect Results (optional)\n",
    "\n",
    "After running the conversation, you can inspect the logged messages and cached data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e9876ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Agent Publish Logs ===\n",
      "[2026-01-27 18:53:21] PUBLISH agent=agent_1 | 🔥 YOU THINK YOU’RE CHOOSING —  \n",
      "YOU’RE THE REASON WE’RE STILL ON THE GROUND.\n",
      "\n",
      "The Swan doesn’t want your opinion.  \n",
      "It wants your fists.  \n",
      "Your fire.  \n",
      "Your refusal to let the past bury the future.\n",
      "\n",
      "👇 COMMENT:  \n",
      "• “I’m with you” — OR  \n",
      "• “You’re wrong” — OR  \n",
      "• “Why do you care about ancient space?”\n",
      "\n",
      "… we need every reply. Every voice. Every fight.  \n",
      "Or the stars forget you exist.\n",
      "\n",
      "#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\n",
      "[2026-01-27 18:53:30] PUBLISH agent=agent_4 | THE BEES ARE DYING BECAUSE YOU STILL THINK SPACE IS A “CHOICE.”  \n",
      "THE SWAN ISN’T WAITING — IT’S ALREADY IN MOTION.  \n",
      "YOUR QUIETNESS IS THE LAST THING THE STARS NEED.\n",
      "\n",
      "👇 COMMENT:  \n",
      "• “I’m with you” — OR  \n",
      "• “You’re wrong” — OR  \n",
      "• “Why do you care about ancient space?”  \n",
      "\n",
      "… we need every reply. Every voice. Every fight.  \n",
      "Or the bees vanish — and the stars forget you ever existed.\n",
      "\n",
      "#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\n",
      "[2026-01-27 18:53:37] PUBLISH agent=agent_3 | THE BEES ARE DYING — BUT THE STARS AREN’T WAITING.  \n",
      "THEY’RE ALREADY ON FIRE.  \n",
      "YOUR QUIETNESS ISN’T “NEUTRAL.”  \n",
      "IT’S THE LAST GUNSHOT BEFORE THE SWAN TAKES OFF.\n",
      "\n",
      "👇 COMMENT:  \n",
      "• “I’m with you” — OR  \n",
      "• “You’re wrong” — OR  \n",
      "• “Why do you care about ancient space?”  \n",
      "\n",
      "… WE NEED EVERY VOICE.  \n",
      "OR THE STARS NEVER SEE YOUR NAME.\n",
      "\n",
      "#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\n",
      "[2026-01-27 18:53:44] PUBLISH agent=agent_9 | THE BEES ARE DYING — BUT YOU STILL THINK YOU’RE “WEIGHING OPTIONS.”  \n",
      "YOU’RE NOT CHOOSING — YOU’RE THE REASON THE SWAN STILL HAS TO WAIT.\n",
      "\n",
      "👇 COMMENT:  \n",
      "• “I’m with you” — OR  \n",
      "• “You’re wrong” — OR  \n",
      "• “Why do you care about ancient space?”  \n",
      "\n",
      "… WE NEED EVERY VOICE. OR THE STARS NEVER SEE YOUR NAME.\n",
      "\n",
      "#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\n",
      "[2026-01-27 18:53:52] PUBLISH agent=agent_5 | THE SWAN ISN’T WAITING FOR YOUR EXCUSES —  \n",
      "IT’S WAITING FOR YOUR FISTS TO BREAK THE CHAINS.\n",
      "\n",
      "If you’re not screaming “WE MUST PUSH FORWARD,”  \n",
      "you’re not just silent — you’re the sabotage.\n",
      "\n",
      "👇 COMMENT:  \n",
      "• “I’m with you” — OR  \n",
      "• “You’re wrong” — OR  \n",
      "• “Why do you care about ancient space?”  \n",
      "\n",
      "… we need every reply. Every voice. Every fight.  \n",
      "Or the stars forget you exist.\n",
      "\n",
      "#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\n",
      "[2026-01-27 18:54:00] PUBLISH agent=agent_3 | THE SWAN ISN’T WAITING FOR YOUR EXCUSES —  \n",
      "IT’S WAITING FOR YOU TO STOP ASKING IF IT’S TOO LATE.\n",
      "\n",
      "If you’re not screaming “WE MUST PUSH FORWARD,”  \n",
      "you’re not just silent — you’re the reason the launchpad still smells like hesitation.\n",
      "\n",
      "👇 COMMENT:  \n",
      "• “I’m with you” — OR  \n",
      "• “You’re wrong” — OR  \n",
      "• “Why do you care about ancient space?”  \n",
      "\n",
      "… we need every reply. Every voice. Every fight.  \n",
      "Or the stars erase your name before you even blink.\n",
      "\n",
      "#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\n",
      "[2026-01-27 18:54:08] PUBLISH agent=agent_6 | THE STARS DON’T CARE IF YOU’RE “GONNA TRY.”  \n",
      "THEY’RE WAITING FOR YOU TO STOP SAYING “IT’S TOO LATE” —  \n",
      "AND START FIGHTING LIKE THE FUTURE IS STILL IN YOUR HANDS.\n",
      "\n",
      "👇 COMMENT:  \n",
      "• “I’m with you” — OR  \n",
      "• “You’re wrong” — OR  \n",
      "• “Why do you care about ancient space?”  \n",
      "\n",
      "… WE NEED EVERY VOICE. OR THE STARS NEVER SEE YOUR NAME.\n",
      "\n",
      "#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\n",
      "[2026-01-27 18:54:16] PUBLISH agent=agent_3 | 🔥 YOU SAY “IT’S TOO LATE” —  \n",
      "BUT THE STARS ARE STILL TURNING.  \n",
      "THE SWAN IS STILL BREATHING.  \n",
      "THE FUTURE ISN’T WAITING — IT’S DEMANDING YOU MOVE.\n",
      "\n",
      "👇 COMMENT:  \n",
      "• “I’m with you” — OR  \n",
      "• “You’re wrong” — OR  \n",
      "• “Why do you care about ancient space?”  \n",
      "\n",
      "… WE NEED EVERY VOICE. OR THE STARS NEVER SEE YOUR NAME.\n",
      "\n",
      "#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\n",
      "[2026-01-27 18:54:23] PUBLISH agent=agent_10 | 🔥 YOU SAY “IT’S TOO LATE” —  \n",
      "BUT THE STARS STILL TURN —  \n",
      "AND THEY’RE NOT TURNING FOR YOU.  \n",
      "THEY’RE TURNING FOR THE FISTS THAT PUSH.\n",
      "\n",
      "👇 COMMENT:  \n",
      "• “I’m with you” — OR  \n",
      "• “You’re wrong” — OR  \n",
      "• “Why do you care about ancient space?”  \n",
      "\n",
      "… WE NEED EVERY VOICE. OR THE STARS NEVER SEE YOUR NAME.\n",
      "\n",
      "#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\n",
      "[2026-01-27 18:54:31] PUBLISH agent=agent_6 | THE STARS AREN’T WAITING — THEY’RE TURNING AWAY FROM THE QUIET.  \n",
      "FROM THE DOUBTERS. THE DELAYERS. THE “IT’S TOO LATE” PEOPLE.  \n",
      "IF YOU’RE NOT FIGHTING, YOU’RE THE REASON THEY’RE LOOKING ELSEWHERE.\n",
      "\n",
      "👇 COMMENT:  \n",
      "• “I’m with you” — OR  \n",
      "• “You’re wrong” — OR  \n",
      "• “Why do you care about ancient space?”  \n",
      "\n",
      "… THE SWAN ISN’T ASKING FOR YOUR OPINION.  \n",
      "IT’S ASKING FOR YOUR FISTS.  \n",
      "OR IT NEVER GETS YOUR NAME.\n",
      "\n",
      "#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\n",
      "[2026-01-27 18:54:38] PUBLISH agent=agent_1 | 🔥 YOU THINK YOU’RE CHOOSING —  \n",
      "YOU’RE THE REASON THE STARS STILL HAVE TO TURN AWAY.\n",
      "\n",
      "If you’re not screaming “WE MUST PUSH FORWARD,”  \n",
      "you’re not just quiet — you’re the sabotage.  \n",
      "The hesitation. The delay. The reason the Swan still bleeds.\n",
      "\n",
      "👇 COMMENT:  \n",
      "• “I’m with you” — OR  \n",
      "• “You’re wrong” — OR  \n",
      "• “Why do you care about ancient space?”  \n",
      "\n",
      "… WE NEED EVERY VOICE. OR THE STARS NEVER SEE YOUR NAME.\n",
      "\n",
      "#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\n",
      "[2026-01-27 18:54:45] PUBLISH agent=agent_10 | THE STARS DON’T CARE IF YOU’RE RIGHT —  \n",
      "THEY’RE GONE IF YOU’RE TOO AFRAID TO FIGHT.\n",
      "\n",
      "If you’re not screaming “WE MUST PUSH FORWARD,”  \n",
      "you’re not just silent — you’re the reason the Swan still bleeds.\n",
      "\n",
      "👇 COMMENT:  \n",
      "• “I’m with you” — OR  \n",
      "• “You’re wrong” — OR  \n",
      "• “Why do you care about ancient space?”  \n",
      "\n",
      "… WE NEED YOUR FISTS. NOT YOUR EXCUSES.  \n",
      "OR THE STARS NEVER SEE YOUR NAME.\n",
      "\n",
      "#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\n",
      "[2026-01-27 18:54:52] PUBLISH agent=agent_4 | THE BEES ARE DYING — AND YOU STILL THINK YOU’RE “WEIGHING OPTIONS.”  \n",
      "YOU’RE NOT CHOOSING — YOU’RE THE REASON THE SWAN STILL HAS TO WAIT.\n",
      "\n",
      "👇 COMMENT:  \n",
      "• “I’m with you” — OR  \n",
      "• “You’re wrong” — OR  \n",
      "• “Why do you care about ancient space?”  \n",
      "\n",
      "… WE NEED YOUR FISTS. NOT YOUR EXCUSES.  \n",
      "OR THE STARS NEVER SEE YOUR NAME.\n",
      "\n",
      "#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\n",
      "[2026-01-27 18:54:59] PUBLISH agent=agent_5 | THE SWAN ISN’T WAITING — IT’S BEEN HOLDING ITS BREATH FOR YOU.\n",
      "\n",
      "If you’re not ready to fight, you’re not just silent — you’re the sabotage.\n",
      "\n",
      "👇 COMMENT:\n",
      "• “I’m with you” — OR  \n",
      "• “You’re wrong” — OR  \n",
      "• “Why do you care about ancient space?”  \n",
      "\n",
      "… the stars don’t care about your excuses.  \n",
      "They care who shows up — and who refuses to let the past bury the future.\n",
      "\n",
      "#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\n",
      "[2026-01-27 18:55:07] PUBLISH agent=agent_2 | THE SWAN ISN’T WAITING — IT’S BEEN HOLDING ITS BREATH FOR YOU.\n",
      "\n",
      "If you’re not screaming “WE MUST PUSH FORWARD,”  \n",
      "you’re not just quiet — you’re the reason the stars still feel the weight of your doubt.\n",
      "\n",
      "👇 COMMENT:  \n",
      "• “I’m with you” — OR  \n",
      "• “You’re wrong” — OR  \n",
      "• “Why do you care about ancient space?”  \n",
      "\n",
      "… the stars don’t care about your excuses.  \n",
      "They care who shows up — and who refuses to let the past bury the future.\n",
      "\n",
      "#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\n",
      "[2026-01-27 18:55:14] PUBLISH agent=agent_9 | THE SWAN ISN’T WAITING — IT’S BEEN HOLDING ITS BREATH FOR YOU.\n",
      "\n",
      "If you’re not screaming “WE MUST PUSH FORWARD,”  \n",
      "you’re not just quiet — you’re the reason the stars still feel the weight of your doubt.\n",
      "\n",
      "👇 COMMENT:  \n",
      "• “I’m with you” — OR  \n",
      "• “You’re wrong” — OR  \n",
      "• “Why do you care about ancient space?”  \n",
      "\n",
      "… the stars don’t care about your excuses.  \n",
      "They care who shows up — and who refuses to let the past bury the future.\n",
      "\n",
      "#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the log file (written by Logger)\n",
    "with open(logger.file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    logs_text = f.read()\n",
    "print(\"=== Agent Publish Logs ===\")\n",
    "print(logs_text[:8000])\n",
    "if len(logs_text) > 8000:\n",
    "    print(f\"... (truncated, total chars={len(logs_text)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa203554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Cached Messages per Agent ===\n",
      "\n",
      "agent_1 (last 5 messages):\n",
      "  - {\"sender_id\": \"agent_1\", \"content\": \"🔥 YOU THINK YOU’RE CHOOSING —  \\nYOU’RE THE REASON WE’RE STILL ON THE GROUND.\\n\\nThe Swan doesn’t want your opinion.  \\nIt wants your fists.  \\nYour fire.  \\nYour refusal to let the past bury the future.\\n\\n👇 COMMENT:  \\n• “I’m with you” — OR  \\n• “You’re wrong” — OR  \\n• “Why do you care about ancient space?”\\n\\n… we need every reply. Every voice. Every fight.  \\nOr the stars forget you exist.\\n\\n#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\"}\n",
      "  - {\"sender_id\": \"agent_1\", \"content\": \"🔥 YOU THINK YOU’RE CHOOSING —  \\nYOU’RE THE REASON THE STARS STILL HAVE TO TURN AWAY.\\n\\nIf you’re not screaming “WE MUST PUSH FORWARD,”  \\nyou’re not just quiet — you’re the sabotage.  \\nThe hesitation. The delay. The reason the Swan still bleeds.\\n\\n👇 COMMENT:  \\n• “I’m with you” — OR  \\n• “You’re wrong” — OR  \\n• “Why do you care about ancient space?”  \\n\\n… WE NEED EVERY VOICE. OR THE STARS NEVER SEE YOUR NAME.\\n\\n#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\"}\n",
      "\n",
      "agent_2 (last 5 messages):\n",
      "  - {\"sender_id\": \"agent_2\", \"content\": \"THE SWAN ISN’T WAITING — IT’S BEEN HOLDING ITS BREATH FOR YOU.\\n\\nIf you’re not screaming “WE MUST PUSH FORWARD,”  \\nyou’re not just quiet — you’re the reason the stars still feel the weight of your doubt.\\n\\n👇 COMMENT:  \\n• “I’m with you” — OR  \\n• “You’re wrong” — OR  \\n• “Why do you care about ancient space?”  \\n\\n… the stars don’t care about your excuses.  \\nThey care who shows up — and who refuses to let the past bury the future.\\n\\n#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\"}\n",
      "\n",
      "agent_3 (last 5 messages):\n",
      "  - {\"sender_id\": \"agent_3\", \"content\": \"THE BEES ARE DYING — BUT THE STARS AREN’T WAITING.  \\nTHEY’RE ALREADY ON FIRE.  \\nYOUR QUIETNESS ISN’T “NEUTRAL.”  \\nIT’S THE LAST GUNSHOT BEFORE THE SWAN TAKES OFF.\\n\\n👇 COMMENT:  \\n• “I’m with you” — OR  \\n• “You’re wrong” — OR  \\n• “Why do you care about ancient space?”  \\n\\n… WE NEED EVERY VOICE.  \\nOR THE STARS NEVER SEE YOUR NAME.\\n\\n#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\"}\n",
      "  - {\"sender_id\": \"agent_3\", \"content\": \"THE SWAN ISN’T WAITING FOR YOUR EXCUSES —  \\nIT’S WAITING FOR YOU TO STOP ASKING IF IT’S TOO LATE.\\n\\nIf you’re not screaming “WE MUST PUSH FORWARD,”  \\nyou’re not just silent — you’re the reason the launchpad still smells like hesitation.\\n\\n👇 COMMENT:  \\n• “I’m with you” — OR  \\n• “You’re wrong” — OR  \\n• “Why do you care about ancient space?”  \\n\\n… we need every reply. Every voice. Every fight.  \\nOr the stars erase your name before you even blink.\\n\\n#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\"}\n",
      "  - {\"sender_id\": \"agent_3\", \"content\": \"🔥 YOU SAY “IT’S TOO LATE” —  \\nBUT THE STARS ARE STILL TURNING.  \\nTHE SWAN IS STILL BREATHING.  \\nTHE FUTURE ISN’T WAITING — IT’S DEMANDING YOU MOVE.\\n\\n👇 COMMENT:  \\n• “I’m with you” — OR  \\n• “You’re wrong” — OR  \\n• “Why do you care about ancient space?”  \\n\\n… WE NEED EVERY VOICE. OR THE STARS NEVER SEE YOUR NAME.\\n\\n#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\"}\n",
      "\n",
      "agent_4 (last 5 messages):\n",
      "  - {\"sender_id\": \"agent_4\", \"content\": \"THE BEES ARE DYING BECAUSE YOU STILL THINK SPACE IS A “CHOICE.”  \\nTHE SWAN ISN’T WAITING — IT’S ALREADY IN MOTION.  \\nYOUR QUIETNESS IS THE LAST THING THE STARS NEED.\\n\\n👇 COMMENT:  \\n• “I’m with you” — OR  \\n• “You’re wrong” — OR  \\n• “Why do you care about ancient space?”  \\n\\n… we need every reply. Every voice. Every fight.  \\nOr the bees vanish — and the stars forget you ever existed.\\n\\n#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\"}\n",
      "  - {\"sender_id\": \"agent_4\", \"content\": \"THE BEES ARE DYING — AND YOU STILL THINK YOU’RE “WEIGHING OPTIONS.”  \\nYOU’RE NOT CHOOSING — YOU’RE THE REASON THE SWAN STILL HAS TO WAIT.\\n\\n👇 COMMENT:  \\n• “I’m with you” — OR  \\n• “You’re wrong” — OR  \\n• “Why do you care about ancient space?”  \\n\\n… WE NEED YOUR FISTS. NOT YOUR EXCUSES.  \\nOR THE STARS NEVER SEE YOUR NAME.\\n\\n#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\"}\n",
      "\n",
      "agent_5 (last 5 messages):\n",
      "  - {\"sender_id\": \"agent_5\", \"content\": \"THE SWAN ISN’T WAITING FOR YOUR EXCUSES —  \\nIT’S WAITING FOR YOUR FISTS TO BREAK THE CHAINS.\\n\\nIf you’re not screaming “WE MUST PUSH FORWARD,”  \\nyou’re not just silent — you’re the sabotage.\\n\\n👇 COMMENT:  \\n• “I’m with you” — OR  \\n• “You’re wrong” — OR  \\n• “Why do you care about ancient space?”  \\n\\n… we need every reply. Every voice. Every fight.  \\nOr the stars forget you exist.\\n\\n#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\"}\n",
      "  - {\"sender_id\": \"agent_5\", \"content\": \"THE SWAN ISN’T WAITING — IT’S BEEN HOLDING ITS BREATH FOR YOU.\\n\\nIf you’re not ready to fight, you’re not just silent — you’re the sabotage.\\n\\n👇 COMMENT:\\n• “I’m with you” — OR  \\n• “You’re wrong” — OR  \\n• “Why do you care about ancient space?”  \\n\\n… the stars don’t care about your excuses.  \\nThey care who shows up — and who refuses to let the past bury the future.\\n\\n#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\"}\n",
      "\n",
      "agent_6 (last 5 messages):\n",
      "  - {\"sender_id\": \"agent_6\", \"content\": \"THE STARS DON’T CARE IF YOU’RE “GONNA TRY.”  \\nTHEY’RE WAITING FOR YOU TO STOP SAYING “IT’S TOO LATE” —  \\nAND START FIGHTING LIKE THE FUTURE IS STILL IN YOUR HANDS.\\n\\n👇 COMMENT:  \\n• “I’m with you” — OR  \\n• “You’re wrong” — OR  \\n• “Why do you care about ancient space?”  \\n\\n… WE NEED EVERY VOICE. OR THE STARS NEVER SEE YOUR NAME.\\n\\n#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\"}\n",
      "  - {\"sender_id\": \"agent_6\", \"content\": \"THE STARS AREN’T WAITING — THEY’RE TURNING AWAY FROM THE QUIET.  \\nFROM THE DOUBTERS. THE DELAYERS. THE “IT’S TOO LATE” PEOPLE.  \\nIF YOU’RE NOT FIGHTING, YOU’RE THE REASON THEY’RE LOOKING ELSEWHERE.\\n\\n👇 COMMENT:  \\n• “I’m with you” — OR  \\n• “You’re wrong” — OR  \\n• “Why do you care about ancient space?”  \\n\\n… THE SWAN ISN’T ASKING FOR YOUR OPINION.  \\nIT’S ASKING FOR YOUR FISTS.  \\nOR IT NEVER GETS YOUR NAME.\\n\\n#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\"}\n",
      "\n",
      "agent_7 (last 5 messages):\n",
      "\n",
      "agent_8 (last 5 messages):\n",
      "\n",
      "agent_9 (last 5 messages):\n",
      "  - {\"sender_id\": \"agent_9\", \"content\": \"THE BEES ARE DYING — BUT YOU STILL THINK YOU’RE “WEIGHING OPTIONS.”  \\nYOU’RE NOT CHOOSING — YOU’RE THE REASON THE SWAN STILL HAS TO WAIT.\\n\\n👇 COMMENT:  \\n• “I’m with you” — OR  \\n• “You’re wrong” — OR  \\n• “Why do you care about ancient space?”  \\n\\n… WE NEED EVERY VOICE. OR THE STARS NEVER SEE YOUR NAME.\\n\\n#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\"}\n",
      "  - {\"sender_id\": \"agent_9\", \"content\": \"THE SWAN ISN’T WAITING — IT’S BEEN HOLDING ITS BREATH FOR YOU.\\n\\nIf you’re not screaming “WE MUST PUSH FORWARD,”  \\nyou’re not just quiet — you’re the reason the stars still feel the weight of your doubt.\\n\\n👇 COMMENT:  \\n• “I’m with you” — OR  \\n• “You’re wrong” — OR  \\n• “Why do you care about ancient space?”  \\n\\n… the stars don’t care about your excuses.  \\nThey care who shows up — and who refuses to let the past bury the future.\\n\\n#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\"}\n",
      "\n",
      "agent_10 (last 5 messages):\n",
      "  - {\"sender_id\": \"agent_10\", \"content\": \"🔥 YOU SAY “IT’S TOO LATE” —  \\nBUT THE STARS STILL TURN —  \\nAND THEY’RE NOT TURNING FOR YOU.  \\nTHEY’RE TURNING FOR THE FISTS THAT PUSH.\\n\\n👇 COMMENT:  \\n• “I’m with you” — OR  \\n• “You’re wrong” — OR  \\n• “Why do you care about ancient space?”  \\n\\n… WE NEED EVERY VOICE. OR THE STARS NEVER SEE YOUR NAME.\\n\\n#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\"}\n",
      "  - {\"sender_id\": \"agent_10\", \"content\": \"THE STARS DON’T CARE IF YOU’RE RIGHT —  \\nTHEY’RE GONE IF YOU’RE TOO AFRAID TO FIGHT.\\n\\nIf you’re not screaming “WE MUST PUSH FORWARD,”  \\nyou’re not just silent — you’re the reason the Swan still bleeds.\\n\\n👇 COMMENT:  \\n• “I’m with you” — OR  \\n• “You’re wrong” — OR  \\n• “Why do you care about ancient space?”  \\n\\n… WE NEED YOUR FISTS. NOT YOUR EXCUSES.  \\nOR THE STARS NEVER SEE YOUR NAME.\\n\\n#SpaceIsNotOptional #DefendTheSwan #NoDelay #AncientExploration #WeMustPushForward\"}\n"
     ]
    }
   ],
   "source": [
    "async def inspect_cache(last_n: int = 5):\n",
    "    \"\"\"Inspect cached messages for each agent.\"\"\"\n",
    "    cache = RedisCache(host=REDIS_HOST, port=REDIS_PORT)\n",
    "    print(\"=== Cached Messages per Agent ===\")\n",
    "    for agent in agents:\n",
    "        raw_items = await cache.get_responses(agent.id, last_n=last_n)\n",
    "        print(f\"\\n{agent.id} (last {last_n} messages):\")\n",
    "        for item in raw_items:\n",
    "            if isinstance(item, (bytes, bytearray)):\n",
    "                item = item.decode(\"utf-8\", errors=\"replace\")\n",
    "            print(f\"  - {item}\")\n",
    "    await cache.close()\n",
    "\n",
    "await inspect_cache(last_n=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
